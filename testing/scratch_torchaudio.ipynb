{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (0.13.1+cu116)\n",
      "Requirement already satisfied: torch==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torchaudio) (1.13.1)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.13.1->torchaudio) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.13.1+cu116'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "torchaudio.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_extension', '_internal', '_torchaudio', '_torchaudio_ffmpeg', 'backend', 'compliance', 'datasets', 'functional', 'get_audio_backend', 'git_version', 'info', 'io', 'kaldi_io', 'list_audio_backends', 'load', 'models', 'pipelines', 'save', 'set_audio_backend', 'sox_effects', 'transforms', 'utils', 'version']\n"
     ]
    }
   ],
   "source": [
    "print(dir(torchaudio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models ['Conformer', 'ConvTasNet', 'DeepSpeech', 'Emformer', 'HDemucs', 'HuBERTPretrainModel', 'Hypothesis', 'RNNT', 'RNNTBeamSearch', 'Tacotron2', 'Wav2Letter', 'Wav2Vec2Model', 'WaveRNN', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_hdemucs', 'conformer', 'conv_tasnet', 'conv_tasnet_base', 'deepspeech', 'emformer', 'emformer_rnnt_base', 'emformer_rnnt_model', 'hdemucs_high', 'hdemucs_low', 'hdemucs_medium', 'hubert_base', 'hubert_large', 'hubert_pretrain_base', 'hubert_pretrain_large', 'hubert_pretrain_model', 'hubert_pretrain_xlarge', 'hubert_xlarge', 'rnnt', 'rnnt_decoder', 'tacotron2', 'wav2letter', 'wav2vec2', 'wav2vec2_base', 'wav2vec2_large', 'wav2vec2_large_lv60k', 'wav2vec2_model', 'wavernn']\n",
      "\n",
      "\n",
      "pipelines ['CONVTASNET_BASE_LIBRI2MIX', 'EMFORMER_RNNT_BASE_LIBRISPEECH', 'HDEMUCS_HIGH_MUSDB', 'HDEMUCS_HIGH_MUSDB_PLUS', 'HUBERT_ASR_LARGE', 'HUBERT_ASR_XLARGE', 'HUBERT_BASE', 'HUBERT_LARGE', 'HUBERT_XLARGE', 'RNNTBundle', 'SourceSeparationBundle', 'TACOTRON2_GRIFFINLIM_CHAR_LJSPEECH', 'TACOTRON2_GRIFFINLIM_PHONE_LJSPEECH', 'TACOTRON2_WAVERNN_CHAR_LJSPEECH', 'TACOTRON2_WAVERNN_PHONE_LJSPEECH', 'Tacotron2TTSBundle', 'VOXPOPULI_ASR_BASE_10K_DE', 'VOXPOPULI_ASR_BASE_10K_EN', 'VOXPOPULI_ASR_BASE_10K_ES', 'VOXPOPULI_ASR_BASE_10K_FR', 'VOXPOPULI_ASR_BASE_10K_IT', 'WAV2VEC2_ASR_BASE_100H', 'WAV2VEC2_ASR_BASE_10M', 'WAV2VEC2_ASR_BASE_960H', 'WAV2VEC2_ASR_LARGE_100H', 'WAV2VEC2_ASR_LARGE_10M', 'WAV2VEC2_ASR_LARGE_960H', 'WAV2VEC2_ASR_LARGE_LV60K_100H', 'WAV2VEC2_ASR_LARGE_LV60K_10M', 'WAV2VEC2_ASR_LARGE_LV60K_960H', 'WAV2VEC2_BASE', 'WAV2VEC2_LARGE', 'WAV2VEC2_LARGE_LV60K', 'WAV2VEC2_XLSR53', 'Wav2Vec2ASRBundle', 'Wav2Vec2Bundle', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_source_separation_pipeline', '_tts', '_wav2vec2', 'rnnt_pipeline']\n",
      "\n",
      "\n",
      "datasets ['CMUARCTIC', 'CMUDict', 'COMMONVOICE', 'DR_VCTK', 'FluentSpeechCommands', 'GTZAN', 'IEMOCAP', 'LIBRISPEECH', 'LIBRITTS', 'LJSPEECH', 'LibriLightLimited', 'LibriMix', 'MUSDB_HQ', 'QUESST14', 'SPEECHCOMMANDS', 'Snips', 'TEDLIUM', 'VCTK_092', 'VoxCeleb1Identification', 'VoxCeleb1Verification', 'YESNO', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'cmuarctic', 'cmudict', 'commonvoice', 'dr_vctk', 'fluentcommands', 'gtzan', 'iemocap', 'librilight_limited', 'librimix', 'librispeech', 'libritts', 'ljspeech', 'musdb_hq', 'quesst14', 'snips', 'speechcommands', 'tedlium', 'utils', 'vctk', 'voxceleb1', 'yesno']\n"
     ]
    }
   ],
   "source": [
    "print('models', dir(torchaudio.models))\n",
    "print('\\n')\n",
    "print('pipelines', dir(torchaudio.pipelines))\n",
    "print('\\n')\n",
    "print('datasets', dir(torchaudio.datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load in module torchaudio.backend.sox_io_backend:\n",
      "\n",
      "load(filepath: str, frame_offset: int = 0, num_frames: int = -1, normalize: bool = True, channels_first: bool = True, format: Optional[str] = None) -> Tuple[torch.Tensor, int]\n",
      "    Load audio data from file.\n",
      "    \n",
      "    Note:\n",
      "        This function can handle all the codecs that underlying libsox can handle,\n",
      "        however it is tested on the following formats;\n",
      "    \n",
      "        * WAV, AMB\n",
      "    \n",
      "            * 32-bit floating-point\n",
      "            * 32-bit signed integer\n",
      "            * 24-bit signed integer\n",
      "            * 16-bit signed integer\n",
      "            * 8-bit unsigned integer (WAV only)\n",
      "    \n",
      "        * MP3\n",
      "        * FLAC\n",
      "        * OGG/VORBIS\n",
      "        * OPUS\n",
      "        * SPHERE\n",
      "        * AMR-NB\n",
      "    \n",
      "        To load ``MP3``, ``FLAC``, ``OGG/VORBIS``, ``OPUS`` and other codecs ``libsox`` does not\n",
      "        handle natively, your installation of ``torchaudio`` has to be linked to ``libsox``\n",
      "        and corresponding codec libraries such as ``libmad`` or ``libmp3lame`` etc.\n",
      "    \n",
      "    By default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\n",
      "    ``float32`` dtype, and the shape of `[channel, time]`.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "       ``normalize`` argument does not perform volume normalization.\n",
      "       It only converts the sample type to `torch.float32` from the native sample\n",
      "       type.\n",
      "    \n",
      "       When the input format is WAV with integer type, such as 32-bit signed integer, 16-bit\n",
      "       signed integer, 24-bit signed integer, and 8-bit unsigned integer, by providing ``normalize=False``,\n",
      "       this function can return integer Tensor, where the samples are expressed within the whole range\n",
      "       of the corresponding dtype, that is, ``int32`` tensor for 32-bit signed PCM,\n",
      "       ``int16`` for 16-bit signed PCM and ``uint8`` for 8-bit unsigned PCM. Since torch does not\n",
      "       support ``int24`` dtype, 24-bit signed PCM are converted to ``int32`` tensors.\n",
      "    \n",
      "       ``normalize`` argument has no effect on 32-bit floating-point WAV and other formats, such as\n",
      "       ``flac`` and ``mp3``.\n",
      "    \n",
      "       For these formats, this function always returns ``float32`` Tensor with values.\n",
      "    \n",
      "    Args:\n",
      "        filepath (path-like object or file-like object):\n",
      "            Source of audio data. When the function is not compiled by TorchScript,\n",
      "            (e.g. ``torch.jit.script``), the following types are accepted;\n",
      "    \n",
      "                  * ``path-like``: file path\n",
      "                  * ``file-like``: Object with ``read(size: int) -> bytes`` method,\n",
      "                    which returns byte string of at most ``size`` length.\n",
      "    \n",
      "            When the function is compiled by TorchScript, only ``str`` type is allowed.\n",
      "    \n",
      "            Note: This argument is intentionally annotated as ``str`` only due to\n",
      "            TorchScript compiler compatibility.\n",
      "        frame_offset (int):\n",
      "            Number of frames to skip before start reading data.\n",
      "        num_frames (int, optional):\n",
      "            Maximum number of frames to read. ``-1`` reads all the remaining samples,\n",
      "            starting from ``frame_offset``.\n",
      "            This function may return the less number of frames if there is not enough\n",
      "            frames in the given file.\n",
      "        normalize (bool, optional):\n",
      "            When ``True``, this function converts the native sample type to ``float32``.\n",
      "            Default: ``True``.\n",
      "    \n",
      "            If input file is integer WAV, giving ``False`` will change the resulting Tensor type to\n",
      "            integer type.\n",
      "            This argument has no effect for formats other than integer WAV type.\n",
      "    \n",
      "        channels_first (bool, optional):\n",
      "            When True, the returned Tensor has dimension `[channel, time]`.\n",
      "            Otherwise, the returned Tensor's dimension is `[time, channel]`.\n",
      "        format (str or None, optional):\n",
      "            Override the format detection with the given format.\n",
      "            Providing the argument might help when libsox can not infer the format\n",
      "            from header or extension.\n",
      "    \n",
      "    Returns:\n",
      "        (torch.Tensor, int): Resulting Tensor and sample rate.\n",
      "            If the input file has integer wav format and ``normalize=False``, then it has\n",
      "            integer type, else ``float32`` type. If ``channels_first=True``, it has\n",
      "            `[channel, time]` else `[time, channel]`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torchaudio.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0017, 0.0024, 0.0029,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0017, 0.0024, 0.0029,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " 48000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torchaudio.load('../data/db short intro.ogg')\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
