{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: speechbrain==0.5.13 in /opt/conda/lib/python3.10/site-packages (0.5.13)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from speechbrain==0.5.13) (1.10.0)\n",
      "Requirement already satisfied: hyperpyyaml in /opt/conda/lib/python3.10/site-packages (from speechbrain==0.5.13) (1.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from speechbrain==0.5.13) (1.22.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from speechbrain==0.5.13) (1.2.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (from speechbrain==0.5.13) (0.13.1+cu116)\n",
      "Requirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from speechbrain==0.5.13) (1.13.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from speechbrain==0.5.13) (0.1.97)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from speechbrain==0.5.13) (0.12.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from speechbrain==0.5.13) (4.64.1)\n",
      "Requirement already satisfied: packaging in /root/.local/lib/python3.10/site-packages (from speechbrain==0.5.13) (23.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->speechbrain==0.5.13) (4.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->speechbrain==0.5.13) (3.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->speechbrain==0.5.13) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from huggingface-hub->speechbrain==0.5.13) (6.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.8 in /opt/conda/lib/python3.10/site-packages (from hyperpyyaml->speechbrain==0.5.13) (0.17.21)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in /opt/conda/lib/python3.10/site-packages (from ruamel.yaml>=0.17.8->hyperpyyaml->speechbrain==0.5.13) (0.2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain==0.5.13) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain==0.5.13) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain==0.5.13) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->speechbrain==0.5.13) (3.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install speechbrain==0.5.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.13'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speechbrain as sb\n",
    "sb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brain', 'Stage', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'alignment', 'core', 'create_experiment_directory', 'dataio', 'decoders', 'f', 'lm', 'lobes', 'nnet', 'os', 'parse_arguments', 'pretrained', 'processing', 'tokenizers', 'utils', 'version']\n"
     ]
    }
   ],
   "source": [
    "print(dir(sb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained ['AudioNormalizer', 'DDP', 'DP', 'DataPipeline', 'EncodeDecodePipelineMixin', 'EncoderASR', 'EncoderClassifier', 'EncoderDecoderASR', 'EndToEndSLU', 'F', 'GraphemeToPhoneme', 'HIFIGAN', 'PaddedBatch', 'PaddedData', 'Pretrained', 'SNREstimator', 'SepformerSeparation', 'SimpleNamespace', 'SpeakerRecognition', 'SpectralMaskEnhancement', 'SyncBatchNorm', 'Tacotron2', 'VAD', 'WaveformEnhancement', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'fetch', 'fetching', 'foreign_class', 'hashlib', 'import_from_path', 'interfaces', 'lengths_arg_exists', 'load_hyperpyyaml', 'logger', 'logging', 'run_on_main', 'sentencepiece', 'speechbrain', 'split_path', 'sys', 'torch', 'torchaudio']\n",
      "\n",
      "\n",
      "dataio ['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'batch', 'dataio', 'dataloader', 'dataset', 'encoder', 'filename', 'iterators', 'legacy', 'os', 'preprocess', 'sampler', 'wer']\n",
      "\n",
      "\n",
      "decoders ['CTCPrefixScorer', 'S2SBaseSearcher', 'S2SBeamSearcher', 'S2SGreedySearcher', 'S2SRNNBeamSearchLM', 'S2SRNNBeamSearchTransformerLM', 'S2SRNNBeamSearcher', 'S2SRNNGreedySearcher', 'S2STransformerBeamSearch', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'batch_filter_seq2seq_output', 'ctc', 'ctc_greedy_decode', 'filter_ctc_output', 'filter_seq2seq_output', 'groupby', 'inflate_tensor', 'length_to_mask', 'mask_by_condition', 'sb', 'seq2seq', 'torch']\n",
      "\n",
      "\n",
      "processing ['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'signal_processing', 'speech_augmentation']\n",
      "\n",
      "\n",
      "tokenizers ['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "print('pretrained', dir(sb.pretrained))\n",
    "print('\\n')\n",
    "print('dataio', dir(sb.dataio))\n",
    "print('\\n')\n",
    "print('decoders', dir(sb.decoders))\n",
    "print('\\n')\n",
    "print('processing', dir(sb.processing))\n",
    "print('\\n')\n",
    "print('tokenizers', dir(sb.tokenizers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.dataio.dataio import read_audio\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download pretrained SpeakerRecognition from SpeechBrain\n",
    "from speechbrain.pretrained import SpeakerRecognition\n",
    "run_opts = {\"device\": \"cuda\"}\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\", \n",
    "                                               savedir=\"../models/speechbrain/spkrec-ecapa-voxceleb\", \n",
    "                                               run_opts=run_opts\n",
    "                                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SpeakerRecognition in module speechbrain.pretrained.interfaces object:\n",
      "\n",
      "class SpeakerRecognition(EncoderClassifier)\n",
      " |  SpeakerRecognition(*args, **kwargs)\n",
      " |  \n",
      " |  A ready-to-use model for speaker recognition. It can be used to\n",
      " |  perform speaker verification with verify_batch().\n",
      " |  \n",
      " |  ```\n",
      " |  Example\n",
      " |  -------\n",
      " |  >>> import torchaudio\n",
      " |  >>> from speechbrain.pretrained import SpeakerRecognition\n",
      " |  >>> # Model is downloaded from the speechbrain HuggingFace repo\n",
      " |  >>> tmpdir = getfixture(\"tmpdir\")\n",
      " |  >>> verification = SpeakerRecognition.from_hparams(\n",
      " |  ...     source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
      " |  ...     savedir=tmpdir,\n",
      " |  ... )\n",
      " |  \n",
      " |  >>> # Perform verification\n",
      " |  >>> signal, fs = torchaudio.load(\"tests/samples/single-mic/example1.wav\")\n",
      " |  >>> signal2, fs = torchaudio.load(\"tests/samples/single-mic/example2.flac\")\n",
      " |  >>> score, prediction = verification.verify_batch(signal, signal2)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SpeakerRecognition\n",
      " |      EncoderClassifier\n",
      " |      Pretrained\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  verify_batch(self, wavs1, wavs2, wav1_lens=None, wav2_lens=None, threshold=0.25)\n",
      " |      Performs speaker verification with cosine distance.\n",
      " |      \n",
      " |      It returns the score and the decision (0 different speakers,\n",
      " |      1 same speakers).\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      wavs1 : Torch.Tensor\n",
      " |              Tensor containing the speech waveform1 (batch, time).\n",
      " |              Make sure the sample rate is fs=16000 Hz.\n",
      " |      wavs2 : Torch.Tensor\n",
      " |              Tensor containing the speech waveform2 (batch, time).\n",
      " |              Make sure the sample rate is fs=16000 Hz.\n",
      " |      wav1_lens: Torch.Tensor\n",
      " |              Tensor containing the relative length for each sentence\n",
      " |              in the length (e.g., [0.8 0.6 1.0])\n",
      " |      wav2_lens: Torch.Tensor\n",
      " |              Tensor containing the relative length for each sentence\n",
      " |              in the length (e.g., [0.8 0.6 1.0])\n",
      " |      threshold: Float\n",
      " |              Threshold applied to the cosine distance to decide if the\n",
      " |              speaker is different (0) or the same (1).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score\n",
      " |          The score associated to the binary verification output\n",
      " |          (cosine distance).\n",
      " |      prediction\n",
      " |          The prediction is 1 if the two signals in input are from the same\n",
      " |          speaker and 0 otherwise.\n",
      " |  \n",
      " |  verify_files(self, path_x, path_y)\n",
      " |      Speaker verification with cosine distance\n",
      " |      \n",
      " |      Returns the score and the decision (0 different speakers,\n",
      " |      1 same speakers).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score\n",
      " |          The score associated to the binary verification output\n",
      " |          (cosine distance).\n",
      " |      prediction\n",
      " |          The prediction is 1 if the two signals in input are from the same\n",
      " |          speaker and 0 otherwise.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  MODULES_NEEDED = ['compute_features', 'mean_var_norm', 'embedding_mode...\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from EncoderClassifier:\n",
      " |  \n",
      " |  classify_batch(self, wavs, wav_lens=None)\n",
      " |      Performs classification on the top of the encoded features.\n",
      " |      \n",
      " |      It returns the posterior probabilities, the index and, if the label\n",
      " |      encoder is specified it also the text label.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      wavs : torch.tensor\n",
      " |          Batch of waveforms [batch, time, channels] or [batch, time]\n",
      " |          depending on the model. Make sure the sample rate is fs=16000 Hz.\n",
      " |      wav_lens : torch.tensor\n",
      " |          Lengths of the waveforms relative to the longest one in the\n",
      " |          batch, tensor of shape [batch]. The longest one should have\n",
      " |          relative length 1.0 and others len(waveform) / max_length.\n",
      " |          Used for ignoring padding.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out_prob\n",
      " |          The log posterior probabilities of each class ([batch, N_class])\n",
      " |      score:\n",
      " |          It is the value of the log-posterior for the best class ([batch,])\n",
      " |      index\n",
      " |          The indexes of the best class ([batch,])\n",
      " |      text_lab:\n",
      " |          List with the text labels corresponding to the indexes.\n",
      " |          (label encoder should be provided).\n",
      " |  \n",
      " |  classify_file(self, path)\n",
      " |      Classifies the given audiofile into the given set of labels.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      path : str\n",
      " |          Path to audio file to classify.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out_prob\n",
      " |          The log posterior probabilities of each class ([batch, N_class])\n",
      " |      score:\n",
      " |          It is the value of the log-posterior for the best class ([batch,])\n",
      " |      index\n",
      " |          The indexes of the best class ([batch,])\n",
      " |      text_lab:\n",
      " |          List with the text labels corresponding to the indexes.\n",
      " |          (label encoder should be provided).\n",
      " |  \n",
      " |  encode_batch(self, wavs, wav_lens=None, normalize=False)\n",
      " |      Encodes the input audio into a single vector embedding.\n",
      " |      \n",
      " |      The waveforms should already be in the model's desired format.\n",
      " |      You can call:\n",
      " |      ``normalized = <this>.normalizer(signal, sample_rate)``\n",
      " |      to get a correctly converted signal in most cases.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      wavs : torch.tensor\n",
      " |          Batch of waveforms [batch, time, channels] or [batch, time]\n",
      " |          depending on the model. Make sure the sample rate is fs=16000 Hz.\n",
      " |      wav_lens : torch.tensor\n",
      " |          Lengths of the waveforms relative to the longest one in the\n",
      " |          batch, tensor of shape [batch]. The longest one should have\n",
      " |          relative length 1.0 and others len(waveform) / max_length.\n",
      " |          Used for ignoring padding.\n",
      " |      normalize : bool\n",
      " |          If True, it normalizes the embeddings with the statistics\n",
      " |          contained in mean_var_norm_emb.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      torch.tensor\n",
      " |          The encoded batch\n",
      " |  \n",
      " |  forward(self, wavs, wav_lens=None)\n",
      " |      Runs the classification\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Pretrained:\n",
      " |  \n",
      " |  load_audio(self, path, savedir='.')\n",
      " |      Load an audio file with this model\"s input spec\n",
      " |      \n",
      " |      When using a speech model, it is important to use the same type of data,\n",
      " |      as was used to train the model. This means for example using the same\n",
      " |      sampling rate and number of channels. It is, however, possible to\n",
      " |      convert a file from a higher sampling rate to a lower one (downsampling).\n",
      " |      Similarly, it is simple to downmix a stereo file to mono.\n",
      " |      The path can be a local path, a web url, or a link to a huggingface repo.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from Pretrained:\n",
      " |  \n",
      " |  from_hparams(source, hparams_file='hyperparams.yaml', pymodule_file='custom.py', overrides={}, savedir=None, use_auth_token=False, revision=None, **kwargs) from builtins.type\n",
      " |      Fetch and load based from outside source based on HyperPyYAML file\n",
      " |      \n",
      " |      The source can be a location on the filesystem or online/huggingface\n",
      " |      \n",
      " |      You can use the pymodule_file to include any custom implementations\n",
      " |      that are needed: if that file exists, then its location is added to\n",
      " |      sys.path before Hyperparams YAML is loaded, so it can be referenced\n",
      " |      in the YAML.\n",
      " |      \n",
      " |      The hyperparams file should contain a \"modules\" key, which is a\n",
      " |      dictionary of torch modules used for computation.\n",
      " |      \n",
      " |      The hyperparams file should contain a \"pretrainer\" key, which is a\n",
      " |      speechbrain.utils.parameter_transfer.Pretrainer\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      source : str\n",
      " |          The location to use for finding the model. See\n",
      " |          ``speechbrain.pretrained.fetching.fetch`` for details.\n",
      " |      hparams_file : str\n",
      " |          The name of the hyperparameters file to use for constructing\n",
      " |          the modules necessary for inference. Must contain two keys:\n",
      " |          \"modules\" and \"pretrainer\", as described.\n",
      " |      pymodule_file : str\n",
      " |          A Python file can be fetched. This allows any custom\n",
      " |          implementations to be included. The file's location is added to\n",
      " |          sys.path before the hyperparams YAML file is loaded, so it can be\n",
      " |          referenced in YAML.\n",
      " |          This is optional, but has a default: \"custom.py\". If the default\n",
      " |          file is not found, this is simply ignored, but if you give a\n",
      " |          different filename, then this will raise in case the file is not\n",
      " |          found.\n",
      " |      overrides : dict\n",
      " |          Any changes to make to the hparams file when it is loaded.\n",
      " |      savedir : str or Path\n",
      " |          Where to put the pretraining material. If not given, will use\n",
      " |          ./pretrained_models/<class-name>-hash(source).\n",
      " |      use_auth_token : bool (default: False)\n",
      " |          If true Hugginface's auth_token will be used to load private models from the HuggingFace Hub,\n",
      " |          default is False because majority of models are public.\n",
      " |      revision : str\n",
      " |          The model revision corresponding to the HuggingFace Hub model revision.\n",
      " |          This is particularly useful if you wish to pin your code to a particular\n",
      " |          version of a model hosted at HuggingFace.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from Pretrained:\n",
      " |  \n",
      " |  HPARAMS_NEEDED = []\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be pickleable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Registers a post hook to be run after module's ``load_state_dict``\n",
      " |      is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearning out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5168], device='cuda:0'), tensor([True], device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, prediction = verification.verify_files('../data/cs12 1m sample.ogg', '../data/cs12 sample2.ogg')\n",
    "score, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2378], device='cuda:0'), tensor([False], device='cuda:0'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, prediction = verification.verify_files('../data/cs12 1m sample.ogg', '../data/crux sample2.ogg')\n",
    "score, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0619], device='cuda:0'), tensor([False], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, prediction = verification.verify_files('../data/cs12 1m sample.ogg', '../data/jadepixie sample2.ogg')\n",
    "score, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1766], device='cuda:0'), tensor([False], device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, prediction = verification.verify_files('../data/cs12 1m sample.ogg', '../data/sam sample2.ogg')\n",
    "score, prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've managed to use Speechbrain to perform speaker verification across two different files.  This is a great first step, but in order to accomplish what I'm thinking I will need to feed it segments tested against a list of known voice samples.  In short, I'm less interested in asking \"is this the same speaker\" and more \"do I know this speaker\".\n",
    "\n",
    "I should find a way to segment the audio file into tokens and test individual tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AudioNormalizer', 'DDP', 'DP', 'DataPipeline', 'EncodeDecodePipelineMixin', 'EncoderASR', 'EncoderClassifier', 'EncoderDecoderASR', 'EndToEndSLU', 'F', 'GraphemeToPhoneme', 'HIFIGAN', 'PaddedBatch', 'PaddedData', 'Pretrained', 'SNREstimator', 'SepformerSeparation', 'SimpleNamespace', 'SpeakerRecognition', 'SpectralMaskEnhancement', 'SyncBatchNorm', 'Tacotron2', 'VAD', 'WaveformEnhancement', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'fetch', 'fetching', 'foreign_class', 'hashlib', 'import_from_path', 'interfaces', 'lengths_arg_exists', 'load_hyperpyyaml', 'logger', 'logging', 'run_on_main', 'sentencepiece', 'speechbrain', 'split_path', 'sys', 'torch', 'torchaudio']\n"
     ]
    }
   ],
   "source": [
    "print(dir(sb.pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Voice Activity Detection\n",
    "from speechbrain.pretrained import VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class VAD in module speechbrain.pretrained.interfaces:\n",
      "\n",
      "class VAD(Pretrained)\n",
      " |  VAD(*args, **kwargs)\n",
      " |  \n",
      " |  A ready-to-use class for Voice Activity Detection (VAD) using a\n",
      " |  pre-trained model.\n",
      " |  \n",
      " |  Example\n",
      " |  -------\n",
      " |  >>> import torchaudio\n",
      " |  >>> from speechbrain.pretrained import VAD\n",
      " |  >>> # Model is downloaded from the speechbrain HuggingFace repo\n",
      " |  >>> tmpdir = getfixture(\"tmpdir\")\n",
      " |  >>> VAD = VAD.from_hparams(\n",
      " |  ...     source=\"speechbrain/vad-crdnn-libriparty\",\n",
      " |  ...     savedir=tmpdir,\n",
      " |  ... )\n",
      " |  \n",
      " |  >>> # Perform VAD\n",
      " |  >>> boundaries = VAD.get_speech_segments(\"tests/samples/single-mic/example1.wav\")\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      VAD\n",
      " |      Pretrained\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *args, **kwargs)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  apply_threshold(self, vad_prob, activation_th=0.5, deactivation_th=0.25)\n",
      " |      Scans the frame-level speech probabilities and applies a threshold\n",
      " |      on them. Speech starts when a value larger than activation_th is\n",
      " |      detected, while it ends when observing a value lower than\n",
      " |      the deactivation_th.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      vad_prob: torch.tensor\n",
      " |          Frame-level speech probabilities.\n",
      " |      activation_th:  float\n",
      " |          Threshold for starting a speech segment.\n",
      " |      deactivation_th: float\n",
      " |          Threshold for ending a speech segment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      vad_th: torch.tensor\n",
      " |          Tensor containing 1 for speech regions and 0 for non-speech regions.\n",
      " |  \n",
      " |  create_chunks(self, x, chunk_size=16384, chunk_stride=16384)\n",
      " |      Splits the input into smaller chunks of size chunk_size with\n",
      " |      an overlap chunk_stride. The chunks are concatenated over\n",
      " |      the batch axis.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      x: torch.Tensor\n",
      " |          Signal to split into chunks.\n",
      " |      chunk_size : str\n",
      " |          The size of each chunk.\n",
      " |      chunk_stride:\n",
      " |          The stride (hop) of each chunk.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      x: torch.Tensor\n",
      " |          A new tensors with the chunks derived from the input signal.\n",
      " |  \n",
      " |  double_check_speech_segments(self, boundaries, audio_file, speech_th=0.5)\n",
      " |      Takes in input the boundaries of the detected speech segments and\n",
      " |      double checks (using the neural VAD) that they actually contain speech.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      boundaries: torch.Tensor\n",
      " |          Tensor containing the boundaries of the speech segments.\n",
      " |      audio_file: path\n",
      " |          The original audio file used to compute vad_out.\n",
      " |      speech_th: float\n",
      " |          Threshold on the mean posterior probability over which speech is\n",
      " |          confirmed. Below that threshold, the segment is re-assigned to a\n",
      " |          non-speech region.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_boundaries\n",
      " |          The boundaries of the segments where speech activity is confirmed.\n",
      " |  \n",
      " |  energy_VAD(self, audio_file, boundaries, activation_th=0.5, deactivation_th=0.0, eps=1e-06)\n",
      " |      Applies energy-based VAD within the detected speech segments.The neural\n",
      " |      network VAD often creates longer segments and tends to merge segments that\n",
      " |      are close with each other.\n",
      " |      \n",
      " |      The energy VAD post-processes can be useful for having a fine-grained voice\n",
      " |      activity detection.\n",
      " |      \n",
      " |      The energy VAD computes the energy within the small chunks. The energy is\n",
      " |      normalized within the segment to have mean 0.5 and +-0.5 of std.\n",
      " |      This helps to set the energy threshold.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      audio_file: path\n",
      " |          Path of the audio file containing the recording. The file is read\n",
      " |          with torchaudio.\n",
      " |      boundaries : str\n",
      " |          Tensor containing the speech boundaries. It can be derived using the\n",
      " |          get_boundaries method.\n",
      " |      activation_th: float\n",
      " |          A new speech segment is started it the energy is above activation_th.\n",
      " |      deactivation_th: float\n",
      " |          The segment is considered ended when the energy is <= deactivation_th.\n",
      " |      eps: float\n",
      " |          Small constant for numerical stability.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_boundaries\n",
      " |          The new boundaries that are post-processed by the energy VAD.\n",
      " |  \n",
      " |  forward(self, wavs, wav_lens=None)\n",
      " |      Gets frame-level speech-activity predictions\n",
      " |  \n",
      " |  get_boundaries(self, prob_th, output_value='seconds')\n",
      " |      Computes the time boundaries where speech activity is detected.\n",
      " |      It takes in input frame-level binary decisions\n",
      " |      (1 for speech, 0 for non-speech) and outputs the begin/end second\n",
      " |      (or sample) of each detected speech region.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      prob_th: torch.tensor\n",
      " |          Frame-level binary decisions (1 for speech frame, 0 for a\n",
      " |          non-speech one).  The tensor can be obtained from apply_threshold.\n",
      " |      put_value: 'seconds' or 'samples'\n",
      " |          When the option 'seconds' is set, the returned boundaries are in\n",
      " |          seconds, otherwise, it reports them in samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      boundaries: torch.tensor\n",
      " |          Tensor containing the start second (or sample) of speech segments\n",
      " |          in even positions and their corresponding end in odd positions\n",
      " |          (e.g, [1.0, 1.5, 5,.0 6.0] means that we have two speech segment;\n",
      " |           one from 1.0 to 1.5 seconds and another from 5.0 to 6.0 seconds).\n",
      " |  \n",
      " |  get_segments(self, boundaries, audio_file, before_margin=0.1, after_margin=0.1)\n",
      " |      Returns a list containing all the detected speech segments.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      boundaries: torch.Tensor\n",
      " |          Tensor containing the boundaries of the speech segments.\n",
      " |      audio_file: path\n",
      " |          The original audio file used to compute vad_out.\n",
      " |      before_margin: float\n",
      " |          Used to cut the segments samples a bit before the detected margin.\n",
      " |      after_margin: float\n",
      " |          Use to cut the segments samples a bit after the detected margin.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      segments: list\n",
      " |          List containing the detected speech segments\n",
      " |  \n",
      " |  get_speech_prob_chunk(self, wavs, wav_lens=None)\n",
      " |      Outputs the frame-level posterior probability for the input audio chunks\n",
      " |      Outputs close to zero refers to time steps with a low probability of speech\n",
      " |      activity, while outputs closer to one likely contain speech.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      wavs : torch.tensor\n",
      " |          Batch of waveforms [batch, time, channels] or [batch, time]\n",
      " |          depending on the model. Make sure the sample rate is fs=16000 Hz.\n",
      " |      wav_lens : torch.tensor\n",
      " |          Lengths of the waveforms relative to the longest one in the\n",
      " |          batch, tensor of shape [batch]. The longest one should have\n",
      " |          relative length 1.0 and others len(waveform) / max_length.\n",
      " |          Used for ignoring padding.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      torch.tensor\n",
      " |          The encoded batch\n",
      " |  \n",
      " |  get_speech_prob_file(self, audio_file, large_chunk_size=30, small_chunk_size=10, overlap_small_chunk=False)\n",
      " |      Outputs the frame-level speech probability of the input audio file\n",
      " |      using the neural model specified in the hparam file. To make this code\n",
      " |      both parallelizable and scalable to long sequences, it uses a\n",
      " |      double-windowing approach.  First, we sequentially read non-overlapping\n",
      " |      large chunks of the input signal.  We then split the large chunks into\n",
      " |      smaller chunks and we process them in parallel.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      audio_file: path\n",
      " |          Path of the audio file containing the recording. The file is read\n",
      " |          with torchaudio.\n",
      " |      large_chunk_size: float\n",
      " |          Size (in seconds) of the large chunks that are read sequentially\n",
      " |          from the input audio file.\n",
      " |      small_chunk_size:\n",
      " |          Size (in seconds) of the small chunks extracted from the large ones.\n",
      " |          The audio signal is processed in parallel within the small chunks.\n",
      " |          Note that large_chunk_size/small_chunk_size must be an integer.\n",
      " |      overlap_small_chunk: bool\n",
      " |          True, creates overlapped small chunks. The probabilities of the\n",
      " |          overlapped chunks are combined using hamming windows.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prob_vad: torch.tensor\n",
      " |          Tensor containing the frame-level speech probabilities for the\n",
      " |          input audio file.\n",
      " |  \n",
      " |  get_speech_segments(self, audio_file, large_chunk_size=30, small_chunk_size=10, overlap_small_chunk=False, apply_energy_VAD=False, double_check=True, close_th=0.25, len_th=0.25, activation_th=0.5, deactivation_th=0.25, en_activation_th=0.5, en_deactivation_th=0.0, speech_th=0.5)\n",
      " |      Detects speech segments within the input file. The input signal can\n",
      " |      be both a short or a long recording. The function computes the\n",
      " |      posterior probabilities on large chunks (e.g, 30 sec), that are read\n",
      " |      sequentially (to avoid storing big signals in memory).\n",
      " |      Each large chunk is, in turn, split into smaller chunks (e.g, 10 seconds)\n",
      " |      that are processed in parallel. The pipeline for detecting the speech\n",
      " |      segments is the following:\n",
      " |          1- Compute posteriors probabilities at the frame level.\n",
      " |          2- Apply a threshold on the posterior probability.\n",
      " |          3- Derive candidate speech segments on top of that.\n",
      " |          4- Apply energy VAD within each candidate segment (optional).\n",
      " |          5- Merge segments that are too close.\n",
      " |          6- Remove segments that are too short.\n",
      " |          7- Double check speech segments (optional).\n",
      " |      \n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      audio_file : str\n",
      " |          Path to audio file.\n",
      " |      large_chunk_size: float\n",
      " |          Size (in seconds) of the large chunks that are read sequentially\n",
      " |          from the input audio file.\n",
      " |      small_chunk_size: float\n",
      " |          Size (in seconds) of the small chunks extracted from the large ones.\n",
      " |          The audio signal is processed in parallel within the small chunks.\n",
      " |          Note that large_chunk_size/small_chunk_size must be an integer.\n",
      " |      overlap_small_chunk: bool\n",
      " |          If True, it creates overlapped small chunks (with 50% overal).\n",
      " |          The probabilities of the overlapped chunks are combined using\n",
      " |          hamming windows.\n",
      " |      apply_energy_VAD: bool\n",
      " |          If True, a energy-based VAD is used on the detected speech segments.\n",
      " |          The neural network VAD often creates longer segments and tends to\n",
      " |          merge close segments together. The energy VAD post-processes can be\n",
      " |          useful for having a fine-grained voice activity detection.\n",
      " |          The energy thresholds is  managed by activation_th and\n",
      " |          deactivation_th (see below).\n",
      " |      double_check: bool\n",
      " |          If True, double checkis (using the neural VAD) that the candidate\n",
      " |          speech segments actually contain speech. A threshold on the mean\n",
      " |          posterior probabilities provided by the neural network is applied\n",
      " |          based on the speech_th parameter (see below).\n",
      " |      activation_th:  float\n",
      " |          Threshold of the neural posteriors above which starting a speech segment.\n",
      " |      deactivation_th: float\n",
      " |          Threshold of the neural posteriors below which ending a speech segment.\n",
      " |      en_activation_th: float\n",
      " |          A new speech segment is started it the energy is above activation_th.\n",
      " |          This is active only if apply_energy_VAD is True.\n",
      " |      en_deactivation_th: float\n",
      " |          The segment is considered ended when the energy is <= deactivation_th.\n",
      " |          This is active only if apply_energy_VAD is True.\n",
      " |      speech_th: float\n",
      " |          Threshold on the mean posterior probability within the candidate\n",
      " |          speech segment. Below that threshold, the segment is re-assigned to\n",
      " |          a non-speech region. This is active only if double_check is True.\n",
      " |      close_th: float\n",
      " |          If the distance between boundaries is smaller than close_th, the\n",
      " |          segments will be merged.\n",
      " |      len_th: float\n",
      " |          If the length of the segment is smaller than close_th, the segments\n",
      " |          will be merged.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      boundaries: torch.tensor\n",
      " |          Tensor containing the start second of speech segments in even\n",
      " |          positions and their corresponding end in odd positions\n",
      " |          (e.g, [1.0, 1.5, 5,.0 6.0] means that we have two speech segment;\n",
      " |           one from 1.0 to 1.5 seconds and another from 5.0 to 6.0 seconds).\n",
      " |  \n",
      " |  merge_close_segments(self, boundaries, close_th=0.25)\n",
      " |      Merges segments that are shorter than the given threshold.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      boundaries : str\n",
      " |          Tensor containing the speech boundaries. It can be derived using the\n",
      " |          get_boundaries method.\n",
      " |      close_th: float\n",
      " |          If the distance between boundaries is smaller than close_th, the\n",
      " |          segments will be merged.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_boundaries\n",
      " |          The new boundaries with the merged segments.\n",
      " |  \n",
      " |  remove_short_segments(self, boundaries, len_th=0.25)\n",
      " |      Removes segments that are too short.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      boundaries : str\n",
      " |          Tensor containing the speech boundaries. It can be derived using the\n",
      " |          get_boundaries method.\n",
      " |      len_th: float\n",
      " |          If the length of the segment is smaller than close_th, the segments\n",
      " |          will be merged.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_boundaries\n",
      " |          The new boundaries without the short segments.\n",
      " |  \n",
      " |  save_boundaries(self, boundaries, save_path=None, print_boundaries=True, audio_file=None)\n",
      " |      Saves the boundaries on a file (and/or prints them)  in a readable format.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      boundaries: torch.tensor\n",
      " |          Tensor containing the speech boundaries. It can be derived using the\n",
      " |          get_boundaries method.\n",
      " |      save_path: path\n",
      " |          When to store the text file containing the speech/non-speech intervals.\n",
      " |      print_boundaries: Bool\n",
      " |          Prints the speech/non-speech intervals in the standard outputs.\n",
      " |      audio_file: path\n",
      " |          Path of the audio file containing the recording. The file is read\n",
      " |          with torchaudio. It is used here to detect the length of the\n",
      " |          signal.\n",
      " |  \n",
      " |  upsample_VAD(self, vad_out, audio_file, time_resolution=0.01)\n",
      " |      Upsamples the output of the vad to help visualization. It creates a\n",
      " |      signal that is 1 when there is speech and 0 when there is no speech.\n",
      " |      The vad signal has the same resolution as the input one and can be\n",
      " |      opened with it (e.g, using audacity) to visually figure out VAD regions.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      vad_out: torch.Tensor\n",
      " |          Tensor containing 1 for each frame of speech and 0 for each non-speech\n",
      " |          frame.\n",
      " |      audio_file: path\n",
      " |          The original audio file used to compute vad_out\n",
      " |      time_resolution : float\n",
      " |          Time resolution of the vad_out signal.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      vad_signal\n",
      " |          The upsampled version of the vad_out tensor.\n",
      " |  \n",
      " |  upsample_boundaries(self, boundaries, audio_file)\n",
      " |      Based on the input boundaries, this method creates a signal that is 1\n",
      " |      when there is speech and 0 when there is no speech.\n",
      " |      The vad signal has the same resolution as the input one and can be\n",
      " |      opened with it (e.g, using audacity) to visually figure out VAD regions.\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      boundaries: torch.Tensor\n",
      " |          Tensor containing the boundaries of the speech segments.\n",
      " |      audio_file: path\n",
      " |          The original audio file used to compute vad_out\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      vad_signal\n",
      " |          The output vad signal with the same resolution of the input one.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  HPARAMS_NEEDED = ['sample_rate', 'time_resolution', 'device']\n",
      " |  \n",
      " |  MODULES_NEEDED = ['compute_features', 'mean_var_norm', 'model']\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Pretrained:\n",
      " |  \n",
      " |  load_audio(self, path, savedir='.')\n",
      " |      Load an audio file with this model\"s input spec\n",
      " |      \n",
      " |      When using a speech model, it is important to use the same type of data,\n",
      " |      as was used to train the model. This means for example using the same\n",
      " |      sampling rate and number of channels. It is, however, possible to\n",
      " |      convert a file from a higher sampling rate to a lower one (downsampling).\n",
      " |      Similarly, it is simple to downmix a stereo file to mono.\n",
      " |      The path can be a local path, a web url, or a link to a huggingface repo.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from Pretrained:\n",
      " |  \n",
      " |  from_hparams(source, hparams_file='hyperparams.yaml', pymodule_file='custom.py', overrides={}, savedir=None, use_auth_token=False, revision=None, **kwargs) from builtins.type\n",
      " |      Fetch and load based from outside source based on HyperPyYAML file\n",
      " |      \n",
      " |      The source can be a location on the filesystem or online/huggingface\n",
      " |      \n",
      " |      You can use the pymodule_file to include any custom implementations\n",
      " |      that are needed: if that file exists, then its location is added to\n",
      " |      sys.path before Hyperparams YAML is loaded, so it can be referenced\n",
      " |      in the YAML.\n",
      " |      \n",
      " |      The hyperparams file should contain a \"modules\" key, which is a\n",
      " |      dictionary of torch modules used for computation.\n",
      " |      \n",
      " |      The hyperparams file should contain a \"pretrainer\" key, which is a\n",
      " |      speechbrain.utils.parameter_transfer.Pretrainer\n",
      " |      \n",
      " |      Arguments\n",
      " |      ---------\n",
      " |      source : str\n",
      " |          The location to use for finding the model. See\n",
      " |          ``speechbrain.pretrained.fetching.fetch`` for details.\n",
      " |      hparams_file : str\n",
      " |          The name of the hyperparameters file to use for constructing\n",
      " |          the modules necessary for inference. Must contain two keys:\n",
      " |          \"modules\" and \"pretrainer\", as described.\n",
      " |      pymodule_file : str\n",
      " |          A Python file can be fetched. This allows any custom\n",
      " |          implementations to be included. The file's location is added to\n",
      " |          sys.path before the hyperparams YAML file is loaded, so it can be\n",
      " |          referenced in YAML.\n",
      " |          This is optional, but has a default: \"custom.py\". If the default\n",
      " |          file is not found, this is simply ignored, but if you give a\n",
      " |          different filename, then this will raise in case the file is not\n",
      " |          found.\n",
      " |      overrides : dict\n",
      " |          Any changes to make to the hparams file when it is loaded.\n",
      " |      savedir : str or Path\n",
      " |          Where to put the pretraining material. If not given, will use\n",
      " |          ./pretrained_models/<class-name>-hash(source).\n",
      " |      use_auth_token : bool (default: False)\n",
      " |          If true Hugginface's auth_token will be used to load private models from the HuggingFace Hub,\n",
      " |          default is False because majority of models are public.\n",
      " |      revision : str\n",
      " |          The model revision corresponding to the HuggingFace Hub model revision.\n",
      " |          This is particularly useful if you wish to pin your code to a particular\n",
      " |          version of a model hosted at HuggingFace.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be pickleable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Registers a post hook to be run after module's ``load_state_dict``\n",
      " |      is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearning out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(VAD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.pretrained import VAD\n",
    "# Model is downloaded from the speechbrain HuggingFace repo\n",
    "detection = VAD.from_hparams(\n",
    "    source=\"speechbrain/vad-crdnn-libriparty\",\n",
    "    savedir=\"../models/speechbrain/vad-crdnn-libriparty\",\n",
    "    run_opts=run_opts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection.hparams.sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The detected sample rate is different from that set in the hparam file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m audio_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/db short intro.ogg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m detection\u001b[39m.\u001b[39;49mget_speech_segments(audio_file)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/speechbrain/pretrained/interfaces.py:1895\u001b[0m, in \u001b[0;36mVAD.get_speech_segments\u001b[0;34m(self, audio_file, large_chunk_size, small_chunk_size, overlap_small_chunk, apply_energy_VAD, double_check, close_th, len_th, activation_th, deactivation_th, en_activation_th, en_deactivation_th, speech_th)\u001b[0m\n\u001b[1;32m   1892\u001b[0m audio_file \u001b[39m=\u001b[39m fetch(fl, source\u001b[39m=\u001b[39msource)\n\u001b[1;32m   1894\u001b[0m \u001b[39m# Computing speech vs non speech probabilities\u001b[39;00m\n\u001b[0;32m-> 1895\u001b[0m prob_chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_speech_prob_file(\n\u001b[1;32m   1896\u001b[0m     audio_file,\n\u001b[1;32m   1897\u001b[0m     large_chunk_size\u001b[39m=\u001b[39;49mlarge_chunk_size,\n\u001b[1;32m   1898\u001b[0m     small_chunk_size\u001b[39m=\u001b[39;49msmall_chunk_size,\n\u001b[1;32m   1899\u001b[0m     overlap_small_chunk\u001b[39m=\u001b[39;49moverlap_small_chunk,\n\u001b[1;32m   1900\u001b[0m )\n\u001b[1;32m   1902\u001b[0m \u001b[39m# Apply a threshold to get candidate speech segments\u001b[39;00m\n\u001b[1;32m   1903\u001b[0m prob_th \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_threshold(\n\u001b[1;32m   1904\u001b[0m     prob_chunks,\n\u001b[1;32m   1905\u001b[0m     activation_th\u001b[39m=\u001b[39mactivation_th,\n\u001b[1;32m   1906\u001b[0m     deactivation_th\u001b[39m=\u001b[39mdeactivation_th,\n\u001b[1;32m   1907\u001b[0m )\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/speechbrain/pretrained/interfaces.py:1075\u001b[0m, in \u001b[0;36mVAD.get_speech_prob_file\u001b[0;34m(self, audio_file, large_chunk_size, small_chunk_size, overlap_small_chunk)\u001b[0m\n\u001b[1;32m   1072\u001b[0m sample_rate, audio_len \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_audio_info(audio_file)\n\u001b[1;32m   1074\u001b[0m \u001b[39mif\u001b[39;00m sample_rate \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_rate:\n\u001b[0;32m-> 1075\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1076\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe detected sample rate is different from that set in the hparam file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1077\u001b[0m     )\n\u001b[1;32m   1079\u001b[0m \u001b[39m# Computing the length (in samples) of the large and small chunks\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m long_chunk_len \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(sample_rate \u001b[39m*\u001b[39m large_chunk_size)\n",
      "\u001b[0;31mValueError\u001b[0m: The detected sample rate is different from that set in the hparam file"
     ]
    }
   ],
   "source": [
    "audio_file = '../data/db short intro.ogg'\n",
    "detection.get_speech_segments(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0017, 0.0024, 0.0029,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0017, 0.0024, 0.0029,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " 48000)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from torchaudio.transforms import Resample\n",
    "waveform, sample_rate = torchaudio.load(audio_file)\n",
    "waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = Resample(orig_freq=sample_rate, new_freq=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_waveform = resampler(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resampled_waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compute_features', 'mean_var_norm', 'model']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAD.upsample_VAD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
