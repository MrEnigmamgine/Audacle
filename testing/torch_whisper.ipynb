{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai-whisper==20230124\n",
    "!pip install torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.22.3)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /root/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.3.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /root/.local/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.6.3 pandas-1.5.3 pyparsing-3.0.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230124\n",
      "0.13.1+cu116\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torchaudio as ta\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(whisper.__version__)\n",
    "print(ta.__version__)\n",
    "\n",
    "model_dir = '../models/whisper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = whisper.load_model('base.en', download_root= model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0017, 0.0024, 0.0029,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0017, 0.0024, 0.0029,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " 48000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav, sr = ta.load('../data/db short intro.ogg')\n",
    "wav, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "# ipd.Audio(wav, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_sample_rate = 16000\n",
    "standard_resampler = ta.transforms.Resample(sr, standard_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled = standard_resampler(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'compression_ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base\u001b[39m.\u001b[39;49mtranscribe(audio\u001b[39m=\u001b[39;49mwav)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:181\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, **decode_options)\u001b[0m\n\u001b[1;32m    178\u001b[0m segment_duration \u001b[39m=\u001b[39m segment\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m HOP_LENGTH \u001b[39m/\u001b[39m SAMPLE_RATE\n\u001b[1;32m    180\u001b[0m decode_options[\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 181\u001b[0m result: DecodingResult \u001b[39m=\u001b[39m decode_with_fallback(segment)\n\u001b[1;32m    182\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(result\u001b[39m.\u001b[39mtokens)\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m no_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:120\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    117\u001b[0m decode_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecode(segment, options)\n\u001b[1;32m    119\u001b[0m needs_fallback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[39mif\u001b[39;00m compression_ratio_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decode_result\u001b[39m.\u001b[39;49mcompression_ratio \u001b[39m>\u001b[39m compression_ratio_threshold:\n\u001b[1;32m    121\u001b[0m     needs_fallback \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# too repetitive\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m logprob_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decode_result\u001b[39m.\u001b[39mavg_logprob \u001b[39m<\u001b[39m logprob_threshold:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'compression_ratio'"
     ]
    }
   ],
   "source": [
    "base.transcribe(audio=wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230124\n",
      "0.13.1+cu116\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'compression_ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m wav, sr \u001b[39m=\u001b[39m ta\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m../data/db short intro.ogg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(wav)) \u001b[39m# torch.Tensor\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m base\u001b[39m.\u001b[39;49mtranscribe(audio\u001b[39m=\u001b[39;49mwav)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:181\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, **decode_options)\u001b[0m\n\u001b[1;32m    178\u001b[0m segment_duration \u001b[39m=\u001b[39m segment\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m HOP_LENGTH \u001b[39m/\u001b[39m SAMPLE_RATE\n\u001b[1;32m    180\u001b[0m decode_options[\u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 181\u001b[0m result: DecodingResult \u001b[39m=\u001b[39m decode_with_fallback(segment)\n\u001b[1;32m    182\u001b[0m tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(result\u001b[39m.\u001b[39mtokens)\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m no_speech_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:120\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    117\u001b[0m decode_result \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecode(segment, options)\n\u001b[1;32m    119\u001b[0m needs_fallback \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[39mif\u001b[39;00m compression_ratio_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decode_result\u001b[39m.\u001b[39;49mcompression_ratio \u001b[39m>\u001b[39m compression_ratio_threshold:\n\u001b[1;32m    121\u001b[0m     needs_fallback \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# too repetitive\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m logprob_threshold \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decode_result\u001b[39m.\u001b[39mavg_logprob \u001b[39m<\u001b[39m logprob_threshold:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'compression_ratio'"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torchaudio as ta\n",
    "\n",
    "print(whisper.__version__) # 20230124\n",
    "print(ta.__version__) # 0.13.1+cu116\n",
    "\n",
    "model_dir = '../models/whisper'\n",
    "base = whisper.load_model('base.en', download_root= model_dir)\n",
    "\n",
    "wav, sr = ta.load('../data/db short intro.ogg')\n",
    "print(type(wav)) # torch.Tensor\n",
    "\n",
    "base.transcribe(audio=wav)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
